{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The colab part is mainly used to obtain results for whisper. For preprocessing, we run it on jupyterlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11618,
     "status": "ok",
     "timestamp": 1759597554405,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "s4WjHJwdZDOJ",
    "outputId": "ff95fcb9-0a67-4338-86af-8c529fa92726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai_whisper-20250625.tar.gz (803 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.8.0+cu126)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.12/dist-packages (from triton>=2->openai-whisper) (75.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->openai-whisper) (1.11.1.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->openai-whisper) (3.0.3)\n",
      "Building wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=25bee514fdeebd76412d238bf66b7fb47969dfe5b7d5c7e8fc922917b3eda29e\n",
      "  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: openai-whisper\n",
      "Successfully installed openai-whisper-20250625\n"
     ]
    }
   ],
   "source": [
    "# installing on colab\n",
    "pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haxHq5-pL5Vp"
   },
   "source": [
    "## Colab is mainly used to speed up the transcription of Whisper data. For transcription at each temperature it took 2-3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 4948,
     "status": "ok",
     "timestamp": 1759597559357,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "XTljvyYjxx44"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "from nltk.corpus import cmudict\n",
    "cmu_dict = cmudict.dict()\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759597566740,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "hYvVDCeaabPU"
   },
   "outputs": [],
   "source": [
    "# files for downloading\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4524,
     "status": "ok",
     "timestamp": 1759597575265,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "SItL4BsbdRZo",
    "outputId": "c021321f-6dc7-4a4b-8178-12b4f3a74a17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 54.0MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model('base.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18308,
     "status": "ok",
     "timestamp": 1759597636430,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "9e_daqeBawjR",
    "outputId": "75f15a5b-5f93-4d85-cb78-d4297b24c1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 97,
     "status": "ok",
     "timestamp": 1759597639399,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "RKHxHPLjN6Up"
   },
   "outputs": [],
   "source": [
    "# Using the base directory to generate a list of filenames, and full filepaths\n",
    "def file_names_paths(mooc_base_dir):\n",
    "    mooc_folders = os.listdir(mooc_base_dir) # display all filenames\n",
    "    mooc_subfolders=[] # the paths of base dir plus word name\n",
    "    for item in mooc_folders:\n",
    "        if not item.endswith('.DS_Store'):\n",
    "            audio = os.path.join(mooc_base_dir,item)\n",
    "            mooc_subfolders.append(audio)\n",
    "    mooc_fnl_subfolders = sorted(mooc_subfolders)# starting from 1, and sorted, so DS. not displayed\n",
    "    mooc_filenames = []\n",
    "    mooc_filepaths = []\n",
    "    flatten_mooc_filenames = []\n",
    "    for subfolder in mooc_fnl_subfolders:\n",
    "        mooc_filepath= sorted(os.listdir(subfolder))\n",
    "        for item in mooc_filepath:\n",
    "            full_path = os.path.join(subfolder, item)\n",
    "            mooc_filepaths.append(full_path)\n",
    "            flatten_mooc_filenames.append(item)\n",
    "    return flatten_mooc_filenames, mooc_filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 11938,
     "status": "ok",
     "timestamp": 1759597679543,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "50vFzAmkMZw6"
   },
   "outputs": [],
   "source": [
    "# Count the intelligibel and unintelligible distribution\n",
    "mooc_base_dir = \"/content/gdrive/MyDrive/Colab Notebooks/file/mooc_audio\"\n",
    "flatten_mooc_filenames, mooc_filepaths = file_names_paths(mooc_base_dir)\n",
    "def count_labels(mooc_filenames):\n",
    "    intelligible_count = 0\n",
    "    unintelligible_count = 0\n",
    "    for x in mooc_filenames:\n",
    "        if x.endswith('1.mp3'):\n",
    "            intelligible_count += 1\n",
    "        else:\n",
    "            unintelligible_count += 1\n",
    "    print(f'There are {intelligible_count} \"intelligible\" labels,')\n",
    "    print(f'and {unintelligible_count } \"unintelligible\" labels')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1759597681758,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "asrj4MK2OUx3",
    "outputId": "72e1ecca-f908-4a72-b755-4d4f5b86a834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10230\n",
      "['series01-s00000-Paul-1.mp3', 'series01-s000011-Paul-0.mp3', 'series01-s000012-Paul-1.mp3', 'series01-s000013a-Paul-0.mp3', 'series01-s000013b-Paul-0.mp3']\n",
      "['/content/gdrive/MyDrive/Colab Notebooks/file/mooc_audio/Paul/series01-s00000-Paul-1.mp3', '/content/gdrive/MyDrive/Colab Notebooks/file/mooc_audio/Paul/series01-s000011-Paul-0.mp3', '/content/gdrive/MyDrive/Colab Notebooks/file/mooc_audio/Paul/series01-s000012-Paul-1.mp3', '/content/gdrive/MyDrive/Colab Notebooks/file/mooc_audio/Paul/series01-s000013a-Paul-0.mp3', '/content/gdrive/MyDrive/Colab Notebooks/file/mooc_audio/Paul/series01-s000013b-Paul-0.mp3']\n"
     ]
    }
   ],
   "source": [
    "# Inspecting\n",
    "print(len(flatten_mooc_filenames))\n",
    "print(flatten_mooc_filenames[0:5])\n",
    "print(mooc_filepaths[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1759597688129,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "AR3RLH0XOZBh",
    "outputId": "8d836b94-63f7-4718-d397-2e202be45e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5726 \"intelligible\" labels,\n",
      "and 4504 \"unintelligible\" labels\n"
     ]
    }
   ],
   "source": [
    "# Calling to show the overall distribution of intelligible and unintelligible labels\n",
    "count_labels(flatten_mooc_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1759597690189,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "bxu-HSNbOcob"
   },
   "outputs": [],
   "source": [
    "# Splitting the filenames and filepaths into equal distributions of test and dev\n",
    "def testdev_split(a, b):\n",
    "    dev_filenames = []\n",
    "    test_filenames = []\n",
    "    dev_filepaths = []\n",
    "    test_filepaths = []\n",
    "    for (i_filename, filename), (i_filepath, filepath) in zip(enumerate(a),enumerate(b)):\n",
    "        if i_filename%2 == 0:\n",
    "            dev_filenames.append(filename)\n",
    "        elif i_filename%2 == 1:\n",
    "            test_filenames.append(filename)\n",
    "    #for i, filepath in enumerate(b):\n",
    "        if i_filepath%2 == 0:\n",
    "            dev_filepaths.append(filepath)\n",
    "        elif i_filepath%2 == 1:\n",
    "            test_filepaths.append(filepath)\n",
    "    return dev_filenames, test_filenames, dev_filepaths, test_filepaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1759597691775,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "IFj2bRioP-Du"
   },
   "outputs": [],
   "source": [
    "# providing the dev and test filenames and full file paths for the task\n",
    "dev_fn, test_fn, dev_fp, test_fp = testdev_split(flatten_mooc_filenames, mooc_filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V97a0ndnL5Vy"
   },
   "source": [
    "## best-of method in whisper transcription to select the 20 results (some overlap) and then unique transcript will later be selected and counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759597699438,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "1uQjxAv7Yfhh"
   },
   "outputs": [],
   "source": [
    "def whisper_top_res(audio_file, temperature):\n",
    "    audiosamp=whisper.load_audio(audio_file)\n",
    "    audiosamp=whisper.pad_or_trim(audiosamp) #pad/trim it to fit 30 seconds\n",
    "    mel = whisper.log_mel_spectrogram(audiosamp).to(model.device)\n",
    "    options = whisper.DecodingOptions(language=\"en\", temperature=temperature, best_of=1)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "\n",
    "    num_samples = 20\n",
    "    res_list= []\n",
    "    scores = []\n",
    "    for _ in range(num_samples):\n",
    "        result = whisper.decode(model, mel, options)\n",
    "        scores.append(result.avg_logprob)\n",
    "        res_list.append({'text':result.text, 'avg_logprob':result.avg_logprob})\n",
    "\n",
    "    return res_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759597700965,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "19aeLnRdYhz4"
   },
   "outputs": [],
   "source": [
    "file_xample = '/content/gdrive/MyDrive/Colab Notebooks/file/dummy_temp/s03_paw_1.mp3'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4191,
     "status": "ok",
     "timestamp": 1759597706698,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "Eh0WGd1SaQls",
    "outputId": "6cfce776-f87b-43fb-fa43-be48d79e21af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Go.', 'avg_logprob': -1.3301070213317872},\n",
       " {'text': 'Both.', 'avg_logprob': -1.302091121673584},\n",
       " {'text': 'Paul?', 'avg_logprob': -1.2505410194396973},\n",
       " {'text': 'Go!', 'avg_logprob': -1.3203139305114746},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.2733623504638671},\n",
       " {'text': 'Go.', 'avg_logprob': -1.2308309555053711},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.2733623504638671},\n",
       " {'text': 'ball.', 'avg_logprob': -2.141057777404785},\n",
       " {'text': 'Go!', 'avg_logprob': -1.3203139305114746},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.3235505104064942},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.3235505104064942},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.5094337463378906},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.2733623504638671},\n",
       " {'text': 'for', 'avg_logprob': -1.2418733835220337},\n",
       " {'text': 'Both.', 'avg_logprob': -1.302091121673584},\n",
       " {'text': 'Pull.', 'avg_logprob': -1.4525264739990233},\n",
       " {'text': 'Go.', 'avg_logprob': -1.2308309555053711},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.2733623504638671},\n",
       " {'text': 'Bo.', 'avg_logprob': -1.3235505104064942},\n",
       " {'text': 'Both.', 'avg_logprob': -1.302091121673584}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whisper_top_res(file_xample, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1759597715663,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "HAdBezGFknC1"
   },
   "outputs": [],
   "source": [
    "# Function to transcribe audio files in a specific folder and save the transcriptions to JSON files\n",
    "def mooc_multi_whisper_transcribe_audio_folder(filenames, filepaths, temperature, transcriptions_info_path, raw_text_path):\n",
    "    raw_text = {}\n",
    "    transcriptions_info = {}\n",
    "\n",
    "    for filename, filepath in zip(filenames, filepaths):\n",
    "        if filename.endswith(\".mp3\"):    # Remove '.mp3' extension from the filename\n",
    "            base_filename = filename[:-4]\n",
    "            parts = base_filename.split('-') # Split filename to extract studentID, word, and trueLabel\n",
    "            studentID = parts[0] + '-' + parts[1]\n",
    "            word = parts[2]\n",
    "            trueLabel = 'intelligible' if parts[3] == '1' else 'unintelligible'\n",
    "\n",
    "            result = whisper_top_res(filepath, temperature) # HERE TEMPERATURE SHOULD BE GIVEN\n",
    "            segments_info = []  # Extract required fields from all segments\n",
    "            segment_info = {\n",
    "                    \"text and avg_logprob\": result # to differ from the 'text_one' since here we have mulitple in a list\n",
    "                    }\n",
    "            segments_info.append(segment_info)\n",
    "\n",
    "            transcriptions_info[base_filename] = {\n",
    "                \"studentID\": studentID,\n",
    "                \"word\": word,\n",
    "                \"trueLabel\": trueLabel,\n",
    "                \"segments\": segments_info\n",
    "            }\n",
    "\n",
    "            raw_text[base_filename] = result\n",
    "    #return transcriptions_info, raw_text\n",
    "    with open(transcriptions_info_path, 'w') as json_file: #and save the detailed transcriptions info to a JSON file\n",
    "        json.dump(transcriptions_info, json_file, indent=4)\n",
    "    print(f\"Transcription info saved to {transcriptions_info_path}\")\n",
    "\n",
    "    with open(raw_text_path, 'w') as json_file: # Save the raw transcriptions to a JSON file\n",
    "        json.dump(raw_text, json_file, indent=4)\n",
    "    print(f\"Raw transcription saved to {raw_text_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MemwLZmoZ5MK"
   },
   "source": [
    "## given the limit of google colab on session time and time taken, transcribing batches at severel temperature values at one time is not viable. Therefore, it is done at one temperature per session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13446,
     "status": "ok",
     "timestamp": 1759597733371,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "OX5P3CXgT9Xs",
    "outputId": "a4da6799-4c36-48f5-88c8-a19263493145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription info saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/multi_raw_info_result_whisper04.json\n",
      "Raw transcription saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/multi_raw_text_result_whisper04.json\n"
     ]
    }
   ],
   "source": [
    "# TESTING with a small number of data at temperature 0.4\n",
    "dum_filepaths = mooc_filepaths[0:10]\n",
    "dum_filenames = flatten_mooc_filenames [0:10]\n",
    "dum_transcriptions_info_path04 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/multi_raw_info_result_whisper04.json'\n",
    "dum_raw_text_path04 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/multi_raw_text_result_whisper04.json'\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(dum_transcriptions_info_path04), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(dum_raw_text_path04), exist_ok=True)\n",
    "# Calling\n",
    "mooc_multi_whisper_transcribe_audio_folder(dum_filenames, dum_filepaths, 0.4, dum_transcriptions_info_path04, dum_raw_text_path04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjqH8ozqVZ0J"
   },
   "outputs": [],
   "source": [
    "# calling dev at temperature 0.1\n",
    "# filenames for development: dev_fn\n",
    "#file paths for development: dev_fp\n",
    "whisper_transcriptions_info_path01 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/whisper01_raw_info_result.json'\n",
    "whisper_raw_text_path01 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/whisper01_raw_text_result.json'\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(whisper_transcriptions_info_path01), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(whisper_raw_text_path01), exist_ok=True)\n",
    "# Calling\n",
    "mooc_multi_whisper_transcribe_audio_folder(dev_fn, dev_fp, 0.1, whisper_transcriptions_info_path01, whisper_raw_text_path01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1756140145854,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "Nn0E37avV-W6",
    "outputId": "3bb126f1-9dec-4569-c0cb-2f31185283f3"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_abe4e92e-9ad1-4840-8da8-3e9d9cc09b54\", \"whisper01_raw_info_result.json\", 16225844)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_e9bc680e-a975-468a-8f4b-e2f178437844\", \"whisper01_raw_text_result.json\", 10177798)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(whisper_transcriptions_info_path01)\n",
    "files.download(whisper_raw_text_path01)\n",
    "# downloaded; took 3 hrs to run one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J_wKPwtnWQsV"
   },
   "outputs": [],
   "source": [
    "# Calling dev at temperature 0.3\n",
    "whisper_transcriptions_info_path03 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/whisper03_raw_info_result.json'\n",
    "whisper_raw_text_path03 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/whisper03_raw_text_result.json'\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(whisper_transcriptions_info_path03), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(whisper_raw_text_path03), exist_ok=True)\n",
    "\n",
    "mooc_multi_whisper_transcribe_audio_folder(dev_fn, dev_fp, 0.3, whisper_transcriptions_info_path03, whisper_raw_text_path03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fqJjWVwku_nS"
   },
   "outputs": [],
   "source": [
    "files.download(whisper_transcriptions_info_path03)\n",
    "files.download(whisper_raw_text_path03)\n",
    "## downloaded; took 3 hrs to run one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KmcKwWOzcuwq"
   },
   "outputs": [],
   "source": [
    "# Calling at temperature 0.5\n",
    "whisper_transcriptions_info_path05 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/whisper05_raw_info_result.json'\n",
    "whisper_raw_text_path05 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/whisper05_raw_text_result.json'\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(whisper_transcriptions_info_path05), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(whisper_raw_text_path05), exist_ok=True)\n",
    "\n",
    "mooc_multi_whisper_transcribe_audio_folder(dev_fn, dev_fp, 0.5, whisper_transcriptions_info_path05, whisper_raw_text_path05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uh3NB5dPvFYB"
   },
   "outputs": [],
   "source": [
    "files.download(whisper_transcriptions_info_path05)\n",
    "files.download(whisper_raw_text_path05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9073731,
     "status": "ok",
     "timestamp": 1756298423630,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "Tk_ALRKJdI2-",
    "outputId": "7beb9767-3b72-4773-b559-143497814e58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription info saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/whisper07_raw_info_result.json\n",
      "Raw transcription saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/whisper07_raw_text_result.json\n"
     ]
    }
   ],
   "source": [
    "# Calling at temperature 0.7\n",
    "whisper_transcriptions_info_path07 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/whisper07_raw_info_result.json'\n",
    "whisper_raw_text_path07 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/whisper07_raw_text_result.json'\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(whisper_transcriptions_info_path07), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(whisper_raw_text_path07), exist_ok=True)\n",
    "\n",
    "mooc_multi_whisper_transcribe_audio_folder(dev_fn, dev_fp, 0.7, whisper_transcriptions_info_path07, whisper_raw_text_path07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1756298675443,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "jynuz462xuVq",
    "outputId": "e6b822e4-704b-4a78-e858-b39f7fdb0852"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c707766c-788f-4af5-a041-8ed4fb5a16d7\", \"whisper07_raw_info_result.json\", 16330428)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_09348b3d-5d53-4ea2-8aff-ea26dba4f7d2\", \"whisper07_raw_text_result.json\", 10282382)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(whisper_transcriptions_info_path07)\n",
    "files.download(whisper_raw_text_path07)\n",
    "##downloaded, took 2.20hrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7369705,
     "status": "ok",
     "timestamp": 1756306053988,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "JsDaYkb5dTwH",
    "outputId": "a7b60eef-675e-4d62-dd9c-e55e0a8042fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription info saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/whisper09_raw_info_result.json\n",
      "Raw transcription saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/whisper09_raw_text_result.json\n"
     ]
    }
   ],
   "source": [
    "# Calling at temperature 0.9\n",
    "\n",
    "whisper_transcriptions_info_path09 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/whisper09_raw_info_result.json'\n",
    "whisper_raw_text_path09 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/whisper09_raw_text_result.json'\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(whisper_transcriptions_info_path09), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(whisper_raw_text_path09), exist_ok=True)\n",
    "\n",
    "mooc_multi_whisper_transcribe_audio_folder(dev_fn, dev_fp, 0.9, whisper_transcriptions_info_path09, whisper_raw_text_path09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1756306083848,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "hQRcM8O8xyBE",
    "outputId": "5950e940-e5cb-4939-bbca-0854744a53b4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_3a5b5fad-ffb2-4d6e-ab6c-c77f90ae7d1c\", \"whisper09_raw_info_result.json\", 16462585)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_1de706f6-2cb1-4ca6-b982-e1d7b3e50602\", \"whisper09_raw_text_result.json\", 10414539)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(whisper_transcriptions_info_path09)\n",
    "files.download(whisper_raw_text_path09)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rK5uyJPLL5V5"
   },
   "outputs": [],
   "source": [
    "# Load the JSON data from a file\n",
    "def load_json(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Preprocesses the text by removing leading spaces and punctuations, and converting to lowercase.\n",
    "def preprocess_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Convert numbers to words if necessary\n",
    "def convert_number_to_word(text):\n",
    "    words = text.split()\n",
    "    converted_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            converted_word = num2words(int(word))  # Convert number to word\n",
    "            converted_words.append(converted_word)\n",
    "        else:\n",
    "            converted_words.append(word)\n",
    "    return ' '.join(converted_words)\n",
    "\n",
    "# Function to retrieve phonetic representations from CMU Pronouncing Dictionary.\n",
    "def get_phonetic_representation(word):\n",
    "    phonetic_representations = cmu_dict.get(word.lower())\n",
    "    if phonetic_representations:\n",
    "        return ' '.join(phonetic_representations[0])  # Join the phonetic representations with space\n",
    "    else:\n",
    "        return 'N/A'  # Return 'N/A' if word not found in dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbXsJ4uSL5V5"
   },
   "source": [
    "### Preprocesses the segment texts and calculates the confidence score for each transcription -- modified version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "p7c88WxAL5V5"
   },
   "outputs": [],
   "source": [
    "def model_preprocess_and_calculate_multi(json_file_path):\n",
    "    data = load_json(json_file_path)\n",
    "    preprocessed_results = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        studentID = value[\"studentID\"]\n",
    "        word = value[\"word\"]\n",
    "        trueLabel = value[\"trueLabel\"]\n",
    "        segments = value[\"segments\"]\n",
    "        true_transcription_stripped = convert_number_to_word(word)  # Convert true transcription to words if necessary\n",
    "        true_phonetic_rep = get_phonetic_representation(true_transcription_stripped) # Get phonetic representations for both true and whisper's transcriptions\n",
    "        # Preprocess text\n",
    "        text_avglog_list = segments[0][\"text and avg_logprob\"]\n",
    "        lst_model_transcription = []\n",
    "        lst_true_phonetic_rep = []\n",
    "        lst_model_phonetic_rep = []\n",
    "        lst_model_judge_phonetic = []\n",
    "        lst_confidence_scores = []\n",
    "        for text in text_avglog_list: ## its a list of dictionary containing text and average log prob\n",
    "            preprocessed_texts = []\n",
    "            ## setting confidence score to 0 if len(SGM) >1\n",
    "            ## SETTING CONFIDENCE SCORE TO 0 if there's no word\n",
    "            if len(text['text']) == 0:\n",
    "                confidence_score = 0\n",
    "                preprocessed_texts.append('')\n",
    "                print(f\"No transcriptions for audio file: {studentID}_{word}\")\n",
    "            else:\n",
    "                avg_logprob = text[\"avg_logprob\"]\n",
    "                confidence_score = round(math.exp(avg_logprob), 3)\n",
    "                preprocessed_text = preprocess_text(text['text'])\n",
    "                preprocessed_texts.append(preprocessed_text)\n",
    "\n",
    "            lst_confidence_scores.append(confidence_score) # collecting confidence scores\n",
    "            # Join and process text for all cases\n",
    "            model_transcription = ' '.join(preprocessed_texts).strip()\n",
    "            model_transcription = convert_number_to_word(model_transcription)  # Convert numbers to words if necessary\n",
    "            lst_model_transcription.append(model_transcription)      # DECIDING NOT USE WHISPER_JUDGE;\n",
    "\n",
    "\n",
    "            lst_true_phonetic_rep.append(true_phonetic_rep)\n",
    "            model_phonetic_rep = get_phonetic_representation(model_transcription)\n",
    "            lst_model_phonetic_rep.append(model_phonetic_rep)\n",
    "            lst_topn=[]  ### NEW CONVERSION OF DATA FORMAT\n",
    "\n",
    "            for a, b, d in zip(lst_model_transcription,lst_confidence_scores,lst_model_phonetic_rep):\n",
    "                dict_new={'model_transcription':a,'confidence score':b,'model_phonetic_rep':d}\n",
    "                lst_topn.append(dict_new)\n",
    " ### SPECIFIC TO WHISPER TO SELECT UNIQUE ONES\n",
    "            lst_uniq_text = [] #unique text list\n",
    "            filtered_lst_topn = [] # filtered item\n",
    "\n",
    "            dummy_result={'model_transcription': 'N/A', 'confidence score': 0, 'model_phonetic_rep': 'N/A'} # To refill when a word has less than three unique results\n",
    "            for item in lst_topn:\n",
    "                if item['model_transcription'] not in lst_uniq_text:\n",
    "                    lst_uniq_text.append(item['model_transcription'])\n",
    "                    filtered_lst_topn.append(item)\n",
    " ### CHOOSING TOP THREE:\n",
    "            if len(filtered_lst_topn) == 1:\n",
    "                final_filtered_topn = [filtered_lst_topn[0],dummy_result,dummy_result] #Not every output has more than 3 results, we fill if any output is less than 3 with dummy_result\n",
    "            if len(filtered_lst_topn) == 2:\n",
    "                final_filtered_topn = [filtered_lst_topn[0],filtered_lst_topn[1],dummy_result]\n",
    "            if len(filtered_lst_topn) >= 3:\n",
    "                 final_filtered_topn = [filtered_lst_topn[0],filtered_lst_topn[1],filtered_lst_topn[2]]\n",
    "\n",
    "\n",
    "        preprocessed_results[key] = {\n",
    "            \"studentID\": studentID,\n",
    "            \"true_transcription\": word,\n",
    "            \"trueLabel\": trueLabel,\n",
    "            \"true_phonetic_rep\":true_phonetic_rep,\n",
    "            \"uniq res\": filtered_lst_topn,\n",
    "            \"top res\": final_filtered_topn # ADPATED\n",
    "            }\n",
    "\n",
    "    return preprocessed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "TWtspNbEL5V5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transcriptions for audio file: series07-s00129_city\n",
      "No transcriptions for audio file: series04-s00009_cot\n",
      "No transcriptions for audio file: series04-s00015_meet\n"
     ]
    }
   ],
   "source": [
    "multi_whisper_transcription_info_07 =  \"./tst_json_files/transcription_output/whisper_raw_transcription_info/whisper07_raw_info_result.json\"\n",
    "# preprocess the json using multi_whisper_preprocess_and_calculate\n",
    "whisper_multi_res07 = model_preprocess_and_calculate_multi(multi_whisper_transcription_info_07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "IoCbqyTOL5V6",
    "outputId": "1e2bf6ad-1842-457e-8cc2-8554e553a4ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "series01-s00000-Paul-1\n",
      "{'studentID': 'series01-s00000', 'word': 'Paul', 'trueLabel': 'intelligible', 'segments': [{'text and avg_logprob': [{'text': 'poll', 'avg_logprob': -1.392437219619751}, {'text': 'poll', 'avg_logprob': -1.8757894039154053}, {'text': 'Paul?', 'avg_logprob': -1.8223232269287108}, {'text': \"I'm a...\", 'avg_logprob': -3.1334122249058316}, {'text': 'Paul?', 'avg_logprob': -1.967156982421875}, {'text': 'Palm.', 'avg_logprob': -2.514944648742676}, {'text': 'Phone.', 'avg_logprob': -1.4076932907104491}, {'text': 'Phone.', 'avg_logprob': -1.8013404846191405}, {'text': 'Pawn.', 'avg_logprob': -1.9184025128682454}, {'text': 'Po.', 'avg_logprob': -2.200906753540039}, {'text': 'Poll.', 'avg_logprob': -1.5466182708740235}, {'text': 'Oh', 'avg_logprob': -1.5360673666000366}, {'text': 'poem', 'avg_logprob': -2.0536837577819824}, {'text': 'Paul', 'avg_logprob': -1.7002261877059937}, {'text': 'poll', 'avg_logprob': -1.63498055934906}, {'text': 'poll', 'avg_logprob': -2.282268762588501}, {'text': 'poll', 'avg_logprob': -1.4266287088394165}, {'text': 'Paul?', 'avg_logprob': -1.9193546295166015}, {'text': 'poll', 'avg_logprob': -3.189046859741211}, {'text': 'Pole.', 'avg_logprob': -1.6747987747192383}]}]}\n"
     ]
    }
   ],
   "source": [
    "# inspecting an example of raw transcription\n",
    "filexample = load_json(multi_whisper_transcription_info_07)\n",
    "print(type(filexample))\n",
    "for key, value in filexample.items():\n",
    "    print(key)\n",
    "    print(value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "BkTi7djSL5V6",
    "outputId": "c3c5a99d-d10b-488b-ca83-797de228215e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model_transcription': 'poll', 'confidence score': 0.248, 'model_phonetic_rep': 'P OW1 L'}, {'model_transcription': 'paul', 'confidence score': 0.162, 'model_phonetic_rep': 'P AO1 L'}, {'model_transcription': 'im a', 'confidence score': 0.044, 'model_phonetic_rep': 'N/A'}]\n"
     ]
    }
   ],
   "source": [
    "# Inspecting collection of transcriptions\n",
    "xam=[]\n",
    "for key, value in whisper_multi_res07.items():\n",
    "   # print (key)\n",
    "    xam.append((value['uniq res']))\n",
    "    print (value['top res'])\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "XzhHLncvL5V7"
   },
   "outputs": [],
   "source": [
    "# obtain process output of transcription\n",
    "list_of_raw_info = [\"./tst_json_files/transcription_output/whisper_raw_transcription_info/whisper01_raw_info_result.json\",\n",
    "                   \"./tst_json_files/transcription_output/whisper_raw_transcription_info/whisper03_raw_info_result.json\",\n",
    "                   \"./tst_json_files/transcription_output/whisper_raw_transcription_info/whisper05_raw_info_result.json\",\n",
    "                   \"./tst_json_files/transcription_output/whisper_raw_transcription_info/whisper07_raw_info_result.json\",\n",
    "                   \"./tst_json_files/transcription_output/whisper_raw_transcription_info/whisper09_raw_info_result.json\"]\n",
    "\n",
    "list_of_output_json_file = [\"./tst_json_files/transcription_output/whisper_processed_output/whisper01_output.json\",\n",
    "                            \"./tst_json_files/transcription_output/whisper_processed_output/whisper03_output.json\",\n",
    "                            \"./tst_json_files/transcription_output/whisper_processed_output/whisper05_output.json\",\n",
    "                            \"./tst_json_files/transcription_output/whisper_processed_output/whisper07_output.json\",\n",
    "                            \"./tst_json_files/transcription_output/whisper_processed_output/whisper09_output.json\"\n",
    "                           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "qC9-ZXrLL5V7",
    "outputId": "a4889e91-4290-4790-86d9-a33b941378da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed results saved to ./tst_json_files/transcription_output/whisper_processed_output/whisper01_output.json\n",
      "Preprocessed results saved to ./tst_json_files/transcription_output/whisper_processed_output/whisper03_output.json\n",
      "No transcriptions for audio file: series06-s00017_knows\n",
      "No transcriptions for audio file: series05-s000073_seedy\n",
      "Preprocessed results saved to ./tst_json_files/transcription_output/whisper_processed_output/whisper05_output.json\n",
      "No transcriptions for audio file: series07-s00129_city\n",
      "No transcriptions for audio file: series04-s00009_cot\n",
      "No transcriptions for audio file: series04-s00015_meet\n",
      "Preprocessed results saved to ./tst_json_files/transcription_output/whisper_processed_output/whisper07_output.json\n",
      "No transcriptions for audio file: series07-s00008_bard\n",
      "No transcriptions for audio file: series07-s00063_bear\n",
      "No transcriptions for audio file: series03-s0000128_beer\n",
      "No transcriptions for audio file: series04-s00028_boy\n",
      "No transcriptions for audio file: series07-s00038_buy\n",
      "No transcriptions for audio file: series07-s00015_city\n",
      "No transcriptions for audio file: series05-s000019_cot\n",
      "No transcriptions for audio file: series07-s00103_daft\n",
      "No transcriptions for audio file: series01-s000032_farther\n",
      "No transcriptions for audio file: series06-s00005_farther\n",
      "No transcriptions for audio file: series04-s00037_hat\n",
      "No transcriptions for audio file: series01-s00000_pore\n",
      "No transcriptions for audio file: series03-s0000225_pore\n",
      "No transcriptions for audio file: series05-s000011_putt\n",
      "No transcriptions for audio file: series03-s0000126_tied\n",
      "Preprocessed results saved to ./tst_json_files/transcription_output/whisper_processed_output/whisper09_output.json\n"
     ]
    }
   ],
   "source": [
    "#CALLING\n",
    "for raw_info, output_json_file in zip(list_of_raw_info, list_of_output_json_file):\n",
    "    result = model_preprocess_and_calculate_multi(raw_info)\n",
    "    with open(output_json_file, 'w') as json_file:\n",
    "        json.dump(result, json_file, indent=4)\n",
    "    print(f\"Preprocessed results saved to {output_json_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "W7nJoxxOL5V7"
   },
   "outputs": [],
   "source": [
    "# A FUNCTION TO FILTER NUMBER OF RESULTS USING PROCESSED RESULTS\n",
    "def filter_topn(whisper_multi_res):\n",
    "    collection_transcript = []\n",
    "    for key, value in whisper_multi_res.items():\n",
    "        collection_transcript.append(value['top res'])\n",
    "    fnl_unique=[]\n",
    "    fnl_lst_full=[]\n",
    "    freq_lst=[]\n",
    "    for collection_lst in collection_transcript:\n",
    "        lst_unique=[]\n",
    "        lst_full=[]\n",
    "        for item in collection_lst:\n",
    "            if item['model_transcription'] not in lst_unique:\n",
    "                lst_unique.append(item['model_transcription'])\n",
    "                lst_full.append(item)\n",
    "        #fnl_unique.append((len(lst_unique),lst_unique))\n",
    "        fnl_lst_full.append((len(lst_full),lst_full))\n",
    "        freq_lst.append(len(lst_full))\n",
    "    return fnl_lst_full, freq_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "IZ4nJimvL5V7"
   },
   "outputs": [],
   "source": [
    "fnl_lst04,freq_lst04 =filter_topn(whisper_multi_res07) # TRYING TO PRINT THE TOP N RESULT OF EACH AUDIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tFqaETlL5V8"
   },
   "source": [
    "print(fnl_lst04[34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "qV8xnherL5V8",
    "outputId": "d63a59f7-9195-4f0d-ca1a-02a6131c7b12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 686, 3: 4429}\n"
     ]
    }
   ],
   "source": [
    "items = freq_lst04\n",
    "counts = {item: items.count(item) for item in set(items)}\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDG7046SL5V8"
   },
   "source": [
    "### Below is the result of how many unique transcrptions are distributed among the transcription at each temperature; for instance at temperature 0.1, there are 3869 results that only have one unique hypothesis , and 946 that have two hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4XiHq9nL5V8"
   },
   "source": [
    "#### Based on the distrubition, I decide to choose 0.3, 0.5 and 0.7 as three temperatures, and selet top 3 unique hypotheses. Moreover, since there are 686-2379 instances where only one hypothesis is available, I add the close to last hypothesis to fill them to 3 hypotheses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uk-jSCinL5V9"
   },
   "outputs": [],
   "source": [
    "# tem_data: temp_0x is the temperature. within the value, a key is the number of unique results and value is the quantity\n",
    "tem_data = {'temp_01': {1: 3869, 2: 946, 3: 217, 4: 58, 5: 16, 6: 6, 7: 1, 10: 2},\n",
    "        'temp_03': {1: 2379, 2: 1257, 3: 645, 4: 379, 5: 209, 6: 102, 7: 63, 8: 35, 9: 23, 10: 11, 11: 5, 13: 4, 15: 1, 16: 1, 18: 1},\n",
    "        'temp_05': {1: 1398, 2: 1057, 3: 758, 4: 554, 5: 365, 6: 285, 7: 235, 8: 139, 9: 113, 10: 72, 11: 51, 12: 33, 13: 22, 14: 16, 15: 5, 16: 8, 17: 1, 18: 3},\n",
    "        'temp_07': {1: 686, 2: 706, 3: 653, 4: 534, 5: 421, 6: 386, 7: 359, 8: 290, 9: 237, 10: 209, 11: 177, 12: 137, 13: 88, 14: 80, 15: 54, 16: 47, 17: 27, 18: 9, 19: 10, 20: 5},\n",
    "        'temp_09': {1: 170, 2: 268, 3: 389, 4: 354, 5: 371, 6: 343, 7: 374, 8: 350, 9: 347, 10: 308, 11: 286, 12: 270, 13: 258, 14: 231, 15: 222, 16: 194, 17: 142, 18: 112, 19: 77, 20: 49}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0p8rwhdfL5V9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # importing tools for visualisation\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4drmiJALL5V9"
   },
   "outputs": [],
   "source": [
    "# Aggregating into bins 1, 2, 3, and 4+\n",
    "def whisper_unique_temp(data, filename):\n",
    "    aggregated = {}\n",
    "    for key, values in data.items():\n",
    "        agg = {\n",
    "        \"1\": values.get(1, 0),\n",
    "        \"2\": values.get(2, 0),\n",
    "        \"3\": values.get(3, 0),\n",
    "        \"4+\": sum(v for k, v in values.items() if k >= 4)\n",
    "        }\n",
    "        aggregated[key] = agg\n",
    "\n",
    "    df = pd.DataFrame(aggregated).T\n",
    "\n",
    "    df.plot(kind=\"bar\", figsize=(10, 6)) #Plotting\n",
    "    plt.title(\"Distribution of Temps across categories (1, 2, 3, 4+)\")\n",
    "    plt.xlabel(\"Temperatures\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend(title=\"Num Uniq Hypotheses\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"./graphs/{filename}\", bbox_inches='tight') # save the figure\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OO-PgfpL5V9",
    "outputId": "6113188b-d592-494f-d38d-f94f763eaab6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calling\n",
    "whisper_unique_temp(tem_data,'distribution_unique_hypo_temps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDT5ZpBpL5V-"
   },
   "source": [
    "### For the testfiles we use colab again to obtain predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8927314,
     "status": "ok",
     "timestamp": 1759606745252,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "xHHW8FOqL5V-",
    "outputId": "ba95cb8b-0ef3-466e-eced-bd3257daec67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription info saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/test_whisper07_raw_info_result.json\n",
      "Raw transcription saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/test_whisper07_raw_text_result.json\n"
     ]
    }
   ],
   "source": [
    "# For testing file we choose temperature at 0.7\n",
    "test_whisper_transcriptions_info_path07 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/test_whisper07_raw_info_result.json'\n",
    "test_whisper_raw_text_path07 = 'content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/test_whisper07_raw_text_result.json'\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(os.path.dirname(test_whisper_transcriptions_info_path07), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(test_whisper_raw_text_path07), exist_ok=True)\n",
    "# Calling\n",
    "mooc_multi_whisper_transcribe_audio_folder(test_fn, test_fp, 0.7, test_whisper_transcriptions_info_path07, test_whisper_raw_text_path07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1759606780212,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "yq8OG0JvL5V-",
    "outputId": "ff06d53e-2126-4151-a508-68baf74aecc4"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_04077bde-09ac-46de-a323-b5451f15cb06\", \"test_whisper07_raw_info_result.json\", 16328399)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_222040b9-0467-4574-9a7d-a34fc27bdf57\", \"test_whisper07_raw_text_result.json\", 10280330)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# took 2 hours 40 mins\n",
    "files.download(test_whisper_transcriptions_info_path07)\n",
    "files.download(test_whisper_raw_text_path07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7vy0TBvL5V_"
   },
   "source": [
    "### Here we test Furong's data, so we need to obtain raw text and transcription information at 0.7 temperature for both development and test data. In comparison with data size of my thesis, the previous is about 1/10 the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759606948341,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "603n92ulL5V_"
   },
   "outputs": [],
   "source": [
    "# we first adapt the transcribe file function\n",
    "## we need to use Furong's code and adapted the 'transcribe' into 'whisper_top_res(filepath)'\n",
    "# Function to transcribe audio files in a specific folder and save the transcriptions to JSON files\n",
    "def fr_transcribe_audio_folder(folder_path, temperature, transcriptions_info_path, raw_text_path):\n",
    "    raw_text = {}\n",
    "    transcriptions_info = {}\n",
    "    filenames = sorted(os.listdir(folder_path)) # added sorted\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith(\".mp3\"):   # Remove '.mp3' extension from the filename\n",
    "            base_filename = filename[:-4]\n",
    "            parts = base_filename.split('_') # Split filename to extract studentID, word, and trueLabel\n",
    "            studentID = parts[0]\n",
    "            word = parts[1]\n",
    "            trueLabel = 'intelligible' if parts[2] == '1' else 'unintelligible'\n",
    "\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            result = whisper_top_res(file_path,temperature)\n",
    "            segments_info = []  # Extract required fields from all segments\n",
    "            segment_info = {\n",
    "                    'text and avg_logprob':result\n",
    "                    }\n",
    "            segments_info.append(segment_info)\n",
    "\n",
    "            transcriptions_info[base_filename] = {\n",
    "                \"studentID\": studentID,\n",
    "                \"word\": word,\n",
    "                \"trueLabel\": trueLabel,\n",
    "                \"segments\": segments_info\n",
    "            }\n",
    "\n",
    "            raw_text[base_filename] = result\n",
    "\n",
    "    # Save the detailed transcriptions info to a JSON file\n",
    "    with open(transcriptions_info_path, 'w') as json_file:\n",
    "        json.dump(transcriptions_info, json_file, indent=4)\n",
    "    print(f\"Transcription info saved to {transcriptions_info_path}\")\n",
    "\n",
    "    # Save the raw transcriptions to a JSON file\n",
    "    with open(raw_text_path, 'w') as json_file:\n",
    "        json.dump(raw_text, json_file, indent=4)\n",
    "    print(f\"Raw transcription saved to {raw_text_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below is to obtain predictions from Furong's test data using temperature 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1759606951977,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "cpQuKL8HL5V_"
   },
   "outputs": [],
   "source": [
    "# defining the base dir for dev and test\n",
    "furong_test_base_dir =  \"/content/gdrive/MyDrive/Colab Notebooks/file/furong_test_all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1759606956064,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "GCI3ZMTpL5V_"
   },
   "outputs": [],
   "source": [
    "# preparing the paths for test at temp 07\n",
    "furong_whisper_test_info_path07 = \"content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/furong_whisper07_test_raw_info_result.json\"\n",
    "furong_whisper_test_raw_text_path07 =  \"content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/furong_whisper07_test_raw_text_result.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2890958,
     "status": "ok",
     "timestamp": 1759609849222,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "35ObVUpSL5V_",
    "outputId": "2171532e-564f-4b6b-8aea-368d1b172bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription info saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_transcription_info/furong_whisper07_test_raw_info_result.json\n",
      "Raw transcription saved to content/gdrive/MyDrive/Colab Notebooks/file/tst_json_files/transcription_output/whisper_raw_text/furong_whisper07_test_raw_text_result.json\n"
     ]
    }
   ],
   "source": [
    "#calling test paths for raw and info\n",
    "os.makedirs(os.path.dirname(furong_whisper_test_info_path07), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(furong_whisper_test_raw_text_path07), exist_ok=True)\n",
    "fr_transcribe_audio_folder(furong_test_base_dir, 0.7, furong_whisper_test_info_path07, furong_whisper_test_raw_text_path07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1759610013450,
     "user": {
      "displayName": "malta zh",
      "userId": "18304279520126745870"
     },
     "user_tz": -120
    },
    "id": "nNEltD4UL5WA",
    "outputId": "6c00e2be-eed5-4a7d-fd2c-5407e33653cc"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_0b8cba94-bba8-452f-8466-ad64e83efd50\", \"furong_whisper07_test_raw_info_result.json\", 6679836)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_f0316908-e1b3-4b96-aae3-41f51c471f26\", \"furong_whisper07_test_raw_text_result.json\", 4205952)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "files.download(furong_whisper_test_info_path07)\n",
    "files.download(furong_whisper_test_raw_text_path07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZwsvHs-v7Mt"
   },
   "source": [
    "## preprocessing the test files\n",
    "### Here the code is implemented on notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "_WsQ7-RXL5WA"
   },
   "outputs": [],
   "source": [
    "# naming the json files\n",
    "test_whisper07_raw_info =  \"./tst_json_files/transcription_output/whisper_raw_transcription_info/test_whisper07_raw_info_result.json\"\n",
    "test_whisper07_output_json_file = \"./tst_json_files/transcription_output/whisper_processed_output/test_whisper07_output.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "3P1bIJsvL5WA",
    "outputId": "ac8a2074-79aa-4e9b-dce8-32b44544f437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transcriptions for audio file: series06-s00034_pore\n",
      "No transcriptions for audio file: series05-s000051_pot\n",
      "Preprocessed results saved to ./tst_json_files/transcription_output/whisper_processed_output/test_whisper07_output.json\n"
     ]
    }
   ],
   "source": [
    "test_whisper07_result = model_preprocess_and_calculate_multi(test_whisper07_raw_info)\n",
    "with open(test_whisper07_output_json_file, 'w') as json_file:\n",
    "    json.dump(test_whisper07_result, json_file, indent=4)\n",
    "print(f\"Preprocessed results saved to {test_whisper07_output_json_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nV_bkmpL5WA"
   },
   "source": [
    "### Here we are using Zou's test datasets. We thus also need to preprocess the test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "gJQhuUhqL5WB"
   },
   "outputs": [],
   "source": [
    "# naming the json files first for test\n",
    "furong_whisper07_test_raw_info =  \"./tst_json_files/transcription_output/whisper_raw_transcription_info/furong_whisper07_test_raw_info_result.json\"\n",
    "furong_whisper07_test_output_json = \"./tst_json_files/transcription_output/whisper_processed_output/furong_whisper07_test_output.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "ryFKIpuBL5WB",
    "outputId": "02aeca12-ec9f-49a3-e6bb-d6f220ff254f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No transcriptions for audio file: s18_boat\n",
      "No transcriptions for audio file: s18_tide\n",
      "Preprocessed results saved to ./tst_json_files/transcription_output/whisper_processed_output/furong_whisper07_test_output.json\n"
     ]
    }
   ],
   "source": [
    "# preprocessing test dataset\n",
    "furong_test_whisper07_result = model_preprocess_and_calculate_multi(furong_whisper07_test_raw_info)\n",
    "with open(furong_whisper07_test_output_json, 'w') as json_file:\n",
    "    json.dump(furong_test_whisper07_result, json_file, indent=4)\n",
    "print(f\"Preprocessed results saved to {furong_whisper07_test_output_json}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
