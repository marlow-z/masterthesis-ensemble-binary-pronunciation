{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dffb20f-d740-4bab-b281-a06ee2f3a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import math\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edf8de9c-91b7-4798-9d12-77f5c74747b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words  # Import num2words for number to word conversion\n",
    "from nltk.corpus import cmudict\n",
    "cmu_dict = cmudict.dict() # Initialize CMU Pronouncing Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4234a06f-407e-40d5-ad54-b1bc27334f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import whisper # whisperopenai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38ea25-3c28-4a30-a035-9727e6f7b4ab",
   "metadata": {},
   "source": [
    "## Preparing filenames and their respective full filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfce206b-43bf-4ca0-bf20-cab8168a1cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the base directory to generate a list of filenames, and full filepaths\n",
    "def file_names_paths(mooc_base_dir):\n",
    "    mooc_folders = os.listdir(mooc_base_dir) # display all filenames\n",
    "    mooc_subfolders=[] # the paths of base dir plus word name\n",
    "    for item in mooc_folders:\n",
    "        audio = os.path.join(mooc_base_dir,item)\n",
    "        mooc_subfolders.append(audio)\n",
    "    mooc_fnl_subfolders = sorted(mooc_subfolders)[1:] # starting from 1, and sorted, so DS. not displayed\n",
    "    mooc_filenames = []\n",
    "    mooc_filepaths = []\n",
    "    flatten_mooc_filenames = []\n",
    "    for subfolder in mooc_fnl_subfolders:\n",
    "        mooc_filepath= sorted(os.listdir(subfolder))\n",
    "        for item in mooc_filepath:\n",
    "            full_path = os.path.join(subfolder, item)\n",
    "            mooc_filepaths.append(full_path)\n",
    "            flatten_mooc_filenames.append(item)\n",
    "    return flatten_mooc_filenames, mooc_filepaths  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6274b43a-2b09-426a-aa7b-1c32f53a3e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the intelligibel and unintelligible distribution\n",
    "mooc_base_dir = \"./mooc_audio\"\n",
    "flatten_mooc_filenames, mooc_filepaths = file_names_paths(mooc_base_dir)\n",
    "def count_labels(mooc_filenames):\n",
    "    intelligible_count = 0\n",
    "    unintelligible_count = 0   \n",
    "    for x in mooc_filenames:\n",
    "        if x.endswith('1.mp3'):\n",
    "            intelligible_count += 1\n",
    "        else:\n",
    "            unintelligible_count += 1\n",
    "    print(f'There are {intelligible_count} \"intelligible\" labels,')\n",
    "    print(f'and {unintelligible_count } \"unintelligible\" labels')\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ac4b8a1-2442-4f32-a0a4-a3cb536c7926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10230\n",
      "['series01-s00000-Paul-1.mp3', 'series01-s000011-Paul-0.mp3', 'series01-s000012-Paul-1.mp3', 'series01-s000013a-Paul-0.mp3', 'series01-s000013b-Paul-0.mp3']\n",
      "['./mooc_audio/Paul/series01-s00000-Paul-1.mp3', './mooc_audio/Paul/series01-s000011-Paul-0.mp3', './mooc_audio/Paul/series01-s000012-Paul-1.mp3', './mooc_audio/Paul/series01-s000013a-Paul-0.mp3', './mooc_audio/Paul/series01-s000013b-Paul-0.mp3']\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "print(len(flatten_mooc_filenames))\n",
    "print(flatten_mooc_filenames[0:5])\n",
    "print(mooc_filepaths[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2b625fe-82cf-41e0-a069-f610301cb063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5726 \"intelligible\" labels,\n",
      "and 4504 \"unintelligible\" labels\n"
     ]
    }
   ],
   "source": [
    "# Calling to show the overall distribution of intelligible and unintelligible labels\n",
    "count_labels(flatten_mooc_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71df01bf-657b-4911-9e3a-24212507126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the filenames and filepaths into equal distributions of test and dev \n",
    "def testdev_split(a, b):\n",
    "    dev_filenames = []\n",
    "    test_filenames = []\n",
    "    dev_filepaths = []\n",
    "    test_filepaths = []\n",
    "    for (i_filename, filename), (i_filepath, filepath) in zip(enumerate(a),enumerate(b)):       \n",
    "        if i_filename%2 == 0:\n",
    "            dev_filenames.append(filename)\n",
    "        elif i_filename%2 == 1:\n",
    "            test_filenames.append(filename)    \n",
    "    #for i, filepath in enumerate(b):  \n",
    "        if i_filepath%2 == 0:\n",
    "            dev_filepaths.append(filepath)\n",
    "        elif i_filepath%2 == 1:\n",
    "            test_filepaths.append(filepath)\n",
    "    return dev_filenames, test_filenames, dev_filepaths, test_filepaths\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f61c7b10-b0ea-4e58-a3f3-fce391eb7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# providing the dev and test filenames and full file paths for the task \n",
    "dev_fn, test_fn, dev_fp, test_fp = testdev_split(flatten_mooc_filenames, mooc_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6abd6983-bb71-400b-bfc6-f0dcc5f4866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['series01-s000026-Paul-0.mp3', 'series01-s000032-Paul-1.mp3', 'series01-s000036-Paul-0.mp3', 'series01-s00004-Paul-0.mp3', 'series01-s000043-Paul-0.mp3']\n",
      "\n",
      "['./mooc_audio/Paul/series01-s00000-Paul-1.mp3', './mooc_audio/Paul/series01-s000012-Paul-1.mp3', './mooc_audio/Paul/series01-s000013b-Paul-0.mp3', './mooc_audio/Paul/series01-s000017-Paul-0.mp3', './mooc_audio/Paul/series01-s000021-Paul-0.mp3', './mooc_audio/Paul/series01-s000026-Paul-0.mp3', './mooc_audio/Paul/series01-s000032-Paul-1.mp3', './mooc_audio/Paul/series01-s000036-Paul-0.mp3', './mooc_audio/Paul/series01-s00004-Paul-0.mp3', './mooc_audio/Paul/series01-s000043-Paul-0.mp3']\n",
      "\n",
      "['series01-s000011-Paul-0.mp3', 'series01-s000013a-Paul-0.mp3', 'series01-s000014-Paul-1.mp3', 'series01-s000018-Paul-0.mp3', 'series01-s000023-Paul-0.mp3', 'series01-s000030-Paul-1.mp3', 'series01-s000034-Paul-0.mp3', 'series01-s000038-Paul-0.mp3', 'series01-s000042-Paul-1.mp3', 'series01-s000046-Paul-0.mp3']\n",
      "\n",
      "['./mooc_audio/Paul/series01-s000011-Paul-0.mp3', './mooc_audio/Paul/series01-s000013a-Paul-0.mp3', './mooc_audio/Paul/series01-s000014-Paul-1.mp3', './mooc_audio/Paul/series01-s000018-Paul-0.mp3', './mooc_audio/Paul/series01-s000023-Paul-0.mp3', './mooc_audio/Paul/series01-s000030-Paul-1.mp3', './mooc_audio/Paul/series01-s000034-Paul-0.mp3', './mooc_audio/Paul/series01-s000038-Paul-0.mp3', './mooc_audio/Paul/series01-s000042-Paul-1.mp3', './mooc_audio/Paul/series01-s000046-Paul-0.mp3']\n"
     ]
    }
   ],
   "source": [
    "print(dev_fn[5:10])\n",
    "print()\n",
    "print(dev_fp[0:10])\n",
    "print()\n",
    "print(test_fn[0:10])\n",
    "print()\n",
    "print(test_fp[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ea88e11-490d-4239-8d90-8a2494218a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2858 \"intelligible\" labels,\n",
      "and 2257 \"unintelligible\" labels\n",
      "There are 2868 \"intelligible\" labels,\n",
      "and 2247 \"unintelligible\" labels\n"
     ]
    }
   ],
   "source": [
    "# counting the intelligible and unintelligible labels\n",
    "distribute_dev = count_labels(dev_fn)\n",
    "distribute_test = count_labels(test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06b975e0-41f6-4d7d-8070-5f8b7f6874cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Whisper English-only BASE model (LATER SWITCH TO OTHER MODEL)\n",
    "model = whisper.load_model('base.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dccaef2-3a80-44a7-8af1-34143ade4fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning it into a function( WITH PRESET TEMPERATURE)\n",
    "def whisper_top_res(audio_file, temperature):\n",
    "    audiosamp=whisper.load_audio(audio_file)\n",
    "    audiosamp=whisper.pad_or_trim(audiosamp) #pad/trim it to fit 30 seconds\n",
    "    mel = whisper.log_mel_spectrogram(audiosamp).to(model.device)\n",
    "    options = whisper.DecodingOptions(language=\"en\", temperature=temperature, best_of=1)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "\n",
    "    num_samples = 20\n",
    "    res_list= []\n",
    "    scores = []\n",
    "    for _ in range(num_samples):\n",
    "        result = whisper.decode(model, mel, options)\n",
    "        scores.append(result.avg_logprob)\n",
    "        res_list.append({'text':result.text, 'avg_logprob':result.avg_logprob})\n",
    "        \n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50c79a5f-6d2a-4ce9-8789-2b9a337e3e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'pause', 'avg_logprob': -1.2353898286819458},\n",
       " {'text': 'pause', 'avg_logprob': -1.6766149997711182},\n",
       " {'text': 'pause', 'avg_logprob': -1.6043052673339844},\n",
       " {'text': 'Buzz.', 'avg_logprob': -1.7566905975341798},\n",
       " {'text': 'pause', 'avg_logprob': -1.5188400745391846},\n",
       " {'text': 'Both.', 'avg_logprob': -1.3413328170776366},\n",
       " {'text': 'pause', 'avg_logprob': -1.2353898286819458},\n",
       " {'text': 'pause', 'avg_logprob': -1.2353898286819458},\n",
       " {'text': 'pause', 'avg_logprob': -1.9460774660110474},\n",
       " {'text': 'pause', 'avg_logprob': -2.0537474155426025},\n",
       " {'text': 'pause', 'avg_logprob': -1.7509652376174927},\n",
       " {'text': 'pause', 'avg_logprob': -1.2353898286819458},\n",
       " {'text': 'pause', 'avg_logprob': -1.2353898286819458},\n",
       " {'text': 'pause', 'avg_logprob': -1.5169219970703125},\n",
       " {'text': 'pause', 'avg_logprob': -1.2353898286819458},\n",
       " {'text': 'Both.', 'avg_logprob': -1.6104118347167968},\n",
       " {'text': 'both.', 'avg_logprob': -1.5019969940185547},\n",
       " {'text': 'pause', 'avg_logprob': -1.988713026046753},\n",
       " {'text': 'Bose.', 'avg_logprob': -1.1890297730763753},\n",
       " {'text': 'z', 'avg_logprob': -3.531306266784668}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing a sample file with temp = 0.4\n",
    "whisper_top_res('previous_data_audio/furong_dev_all/s03_pause_1.mp3', 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c391c0a-219a-4a4e-a46a-d90e182709ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['series01-s00000-Paul-1.mp3', 'series01-s000012-Paul-1.mp3', 'series01-s000013b-Paul-0.mp3', 'series01-s000017-Paul-0.mp3', 'series01-s000021-Paul-0.mp3', 'series01-s000026-Paul-0.mp3', 'series01-s000032-Paul-1.mp3', 'series01-s000036-Paul-0.mp3', 'series01-s00004-Paul-0.mp3', 'series01-s000043-Paul-0.mp3', 'series01-s00007-Paul-1.mp3', 'series02-s00000-Paul-1.mp3', 'series02-s00008-Paul-1.mp3', 'series02-s00016-Paul-1.mp3', 'series02-s00021-Paul-0.mp3']\n",
      "\n",
      "['./mooc_audio/Paul/series01-s00000-Paul-1.mp3', './mooc_audio/Paul/series01-s000012-Paul-1.mp3', './mooc_audio/Paul/series01-s000013b-Paul-0.mp3', './mooc_audio/Paul/series01-s000017-Paul-0.mp3', './mooc_audio/Paul/series01-s000021-Paul-0.mp3', './mooc_audio/Paul/series01-s000026-Paul-0.mp3', './mooc_audio/Paul/series01-s000032-Paul-1.mp3', './mooc_audio/Paul/series01-s000036-Paul-0.mp3', './mooc_audio/Paul/series01-s00004-Paul-0.mp3', './mooc_audio/Paul/series01-s000043-Paul-0.mp3', './mooc_audio/Paul/series01-s00007-Paul-1.mp3', './mooc_audio/Paul/series02-s00000-Paul-1.mp3', './mooc_audio/Paul/series02-s00008-Paul-1.mp3', './mooc_audio/Paul/series02-s00016-Paul-1.mp3', './mooc_audio/Paul/series02-s00021-Paul-0.mp3']\n"
     ]
    }
   ],
   "source": [
    "## Using dummy files\n",
    "filenames_dm = dev_fn[0:15]\n",
    "filepaths_dm = dev_fp[0:15]\n",
    "print(filenames_dm)\n",
    "print()\n",
    "print(filepaths_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b5f7d3-859a-4a84-97bf-0ab3deb73640",
   "metadata": {},
   "source": [
    "## *Transcribing multiple predictions using whisper like wav2vec's multi_w2v_transcribe_audio_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96535b65-2a54-4576-8cc5-c91ca6c43219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to transcribe audio files in a specific folder and save the transcriptions to JSON files\n",
    "def mooc_multi_whisper_transcribe_audio_folder(filenames, filepaths, temperature, transcriptions_info_path, raw_text_path):    \n",
    "    raw_text = {}\n",
    "    transcriptions_info = {}\n",
    "\n",
    "    for filename, filepath in zip(filenames, filepaths):\n",
    "        if filename.endswith(\".mp3\"):    # Remove '.mp3' extension from the filename        \n",
    "            base_filename = filename[:-4]                        \n",
    "            parts = base_filename.split('-') # Split filename to extract studentID, word, and trueLabel\n",
    "            studentID = parts[0] + '-' + parts[1]\n",
    "            word = parts[2]\n",
    "            trueLabel = 'intelligible' if parts[3] == '1' else 'unintelligible'  \n",
    "\n",
    "            result = whisper_top_res(filepath, temperature) # HERE TEMPERATURE SHOULD BE GIVEN        \n",
    "            segments_info = []  # Extract required fields from all segments\n",
    "            segment_info = {\n",
    "                    \"text and avg_logprob\": result # to differ from the 'text_one' since here we have mulitple in a list\n",
    "                    }\n",
    "            segments_info.append(segment_info)\n",
    "\n",
    "            transcriptions_info[base_filename] = {\n",
    "                \"studentID\": studentID,\n",
    "                \"word\": word,\n",
    "                \"trueLabel\": trueLabel,\n",
    "                \"segments\": segments_info \n",
    "            }\n",
    "\n",
    "            raw_text[base_filename] = result\n",
    "    #return transcriptions_info, raw_text\n",
    "    with open(transcriptions_info_path, 'w') as json_file: #and save the detailed transcriptions info to a JSON file\n",
    "        json.dump(transcriptions_info, json_file, indent=4)\n",
    "    print(f\"Transcription info saved to {transcriptions_info_path}\")\n",
    "    \n",
    "    with open(raw_text_path, 'w') as json_file: # Save the raw transcriptions to a JSON file\n",
    "        json.dump(raw_text, json_file, indent=4)\n",
    "    print(f\"Raw transcription saved to {raw_text_path}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dc06d33-6bac-4842-82e5-b56b4e935c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mooc_multi_batch_transcribe_with_different_temperatures(filenames, filepaths, temperature_values, info_paths, raw_text_paths):\n",
    "    for temp, info_path, raw_text_path in zip(temperature_values, info_paths, raw_text_paths):\n",
    "        mooc_multi_whisper_transcribe_audio_folder(filenames, filepaths, temp, info_path, raw_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b9acccbb-9578-4069-b559-6f379c349b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the info_path follow similar naming convention of wav2vec \n",
    "dummy_temperature_values = [0.4, 0.5]\n",
    "\n",
    "# but the whisper folders have no 'whisper' so it is added to the \"result\" of json\n",
    "dummy_multi_whisper_transcription_info_paths =  [\"./tst_json_files/transcription_output/whisper_raw_transcription_info/multi_raw_info_result_whisper04.json\",\n",
    "                                               \"./tst_json_files/transcription_output/whisper_raw_transcription_info/multi_raw_info_result_whisper05.json\"]\n",
    "\n",
    "dummy_multi_whisper_raw_text_paths =  [\"./tst_json_files/transcription_output/raw_text/multi_raw_text_result_whisper04.json\",\n",
    "                                     \"./tst_json_files/transcription_output/raw_text/multi_raw_text_result_whisper05.json\",]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3569ca1b-15dd-4be6-a44e-8a8fe3ebbb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CALLING\n",
    "# DUMMY VERSION\n",
    "mooc_multi_batch_transcribe_with_different_temperatures(filenames_dm,filepaths_dm, dummy_temperature_values, dummy_multi_whisper_transcription_info_paths, dummy_multi_whisper_raw_text_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaf8a35-f243-452f-b825-7a97fe4416a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data from a file\n",
    "def load_json(json_file_path):\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Preprocesses the text by removing leading spaces and punctuations, and converting to lowercase.\n",
    "def preprocess_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Convert numbers to words if necessary\n",
    "def convert_number_to_word(text):\n",
    "    words = text.split()\n",
    "    converted_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            converted_word = num2words(int(word))  # Convert number to word\n",
    "            converted_words.append(converted_word)\n",
    "        else:\n",
    "            converted_words.append(word)\n",
    "    return ' '.join(converted_words)\n",
    "\n",
    "# Function to retrieve phonetic representations from CMU Pronouncing Dictionary.\n",
    "def get_phonetic_representation(word):\n",
    "    phonetic_representations = cmu_dict.get(word.lower())\n",
    "    if phonetic_representations:\n",
    "        return ' '.join(phonetic_representations[0])  # Join the phonetic representations with space\n",
    "    else:\n",
    "        return 'N/A'  # Return 'N/A' if word not found in dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeed099-aede-4c86-ae16-4009334bbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING DUMMY\n",
    "dummy04 = \"./tst_json_files/transcription_output/raw_transcription_info/multi_raw_info_result_whisper04.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf785adf-4ec7-4036-a5a9-412457201439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesses the segment texts and calculates the confidence score for each transcription -- modified version\n",
    "def model_preprocess_and_calculate_multi(json_file_path):\n",
    "    data = load_json(json_file_path)\n",
    "    preprocessed_results = {}\n",
    "\n",
    "    for key, value in data.items():\n",
    "        studentID = value[\"studentID\"]\n",
    "        word = value[\"word\"]\n",
    "        trueLabel = value[\"trueLabel\"]\n",
    "        segments = value[\"segments\"]\n",
    "        true_transcription_stripped = convert_number_to_word(word)  # Convert true transcription to words if necessary                   \n",
    "        true_phonetic_rep = get_phonetic_representation(true_transcription_stripped) # Get phonetic representations for both true and whisper's transcriptions\n",
    "        # Preprocess text        \n",
    "        text_avglog_list = segments[0][\"text and avg_logprob\"] \n",
    "        lst_model_transcription = []\n",
    "        lst_true_phonetic_rep = []\n",
    "        lst_model_phonetic_rep = []\n",
    "        lst_model_judge_phonetic = []        \n",
    "        lst_confidence_scores = []\n",
    "        for text in text_avglog_list: ## its a list of dictionary containing text and average log prob\n",
    "            preprocessed_texts = []\n",
    "            ## setting confidence score to 0 if len(SGM) >1\n",
    "            ## SETTING CONFIDENCE SCORE TO 0 if there's no word\n",
    "            if len(text['text']) == 0:\n",
    "                confidence_score = 0               \n",
    "                preprocessed_texts.append('')\n",
    "                print(f\"No transcriptions for audio file: {studentID}_{word}\") \n",
    "            else:\n",
    "                avg_logprob = text[\"avg_logprob\"]\n",
    "                confidence_score = round(math.exp(avg_logprob), 3)\n",
    "                preprocessed_text = preprocess_text(text['text'])\n",
    "                preprocessed_texts.append(preprocessed_text) \n",
    "            \n",
    "            lst_confidence_scores.append(confidence_score) # collecting confidence scores\n",
    "            # Join and process text for all cases\n",
    "            model_transcription = ' '.join(preprocessed_texts).strip()\n",
    "            model_transcription = convert_number_to_word(model_transcription)  # Convert numbers to words if necessary \n",
    "            lst_model_transcription.append(model_transcription)      # DECIDING NOT USE WHISPER_JUDGE;             \n",
    "                      \n",
    "            lst_true_phonetic_rep.append(true_phonetic_rep)\n",
    "            model_phonetic_rep = get_phonetic_representation(model_transcription)\n",
    "            lst_model_phonetic_rep.append(model_phonetic_rep)       \n",
    "            lst_topn=[]  ### NEW CONVERSION OF DATA FORMAT\n",
    "            for a, b, d in zip(lst_model_transcription,lst_confidence_scores,lst_model_phonetic_rep):\n",
    "                dict_new={'model_transcription':a,'confidence score':b,'model_phonetic_rep':d}\n",
    "                lst_topn.append(dict_new)\n",
    "            \n",
    "        preprocessed_results[key] = {\n",
    "            \"studentID\": studentID,\n",
    "            \"true_transcription\": word,\n",
    "            \"trueLabel\": trueLabel,\n",
    "            \"true_phonetic_rep\":true_phonetic_rep,\n",
    "            \"top res\": lst_topn\n",
    "            }\n",
    "   \n",
    "    return preprocessed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67f6b1-53fe-4821-9b01-e02ded84f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the json file path FOR EXAMPLE TEMPERATURE 0.4\n",
    "multi_whisper_transcription_info_path04 =  \"./tst_json_files/transcription_output/raw_transcription_info/multi_raw_info_1result_whisper04.json\"\n",
    "# preprocess the json using multi_whisper_preprocess_and_calculate\n",
    "whisper_multi_res04 = model_preprocess_and_calculate_multi(multi_whisper_transcription_info_path04)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a04db-bc7b-4815-94b0-9165f3845975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the output_path\n",
    "multi_whisper_output_json_file_path04 = \"./tst_json_files/transcription_output/processed_output/multi_whisper_output04.json\"\n",
    "\n",
    "with open(multi_whisper_output_json_file_path04, 'w') as json_file:\n",
    "    json.dump(whisper_multi_res04, json_file, indent=4)\n",
    "print(f\"Preprocessed results saved to {multi_whisper_output_json_file_path04}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e451e56-ae04-4737-828e-8797466bdfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A FUNCTION TO FILTER NUMBER OF RESULTS USING PROCESSED RESULTS\n",
    "def filter_topn(whisper_multi_res):\n",
    "    collection_transcript = []\n",
    "    for key, value in whisper_multi_res.items():\n",
    "        collection_transcript.append(value['top res'])\n",
    "    fnl_unique=[]\n",
    "    fnl_lst_full=[]\n",
    "    freq_lst=[]\n",
    "    for collection_lst in collection_transcript:\n",
    "        lst_unique=[]\n",
    "        lst_full=[]\n",
    "        for item in collection_lst:   \n",
    "            if item['whisper_transcription'] not in lst_unique:\n",
    "                lst_unique.append(item['whisper_transcription']) \n",
    "                lst_full.append(item)\n",
    "        #fnl_unique.append((len(lst_unique),lst_unique))\n",
    "        fnl_lst_full.append((len(lst_full),lst_full))\n",
    "        freq_lst.append(len(lst_full))\n",
    "    return fnl_lst_full, freq_lst\n",
    "    #print(lst_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8db15-410e-4b71-afb2-9842560bfc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnl_lst04,freq_lst04 =filter_topn(whisper_multi_res04) # TRYING TO PRINT THE TOP N RESULT OF EACH AUDIO\n",
    "print(freq_lst04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac946833-fcae-46ce-a3cc-aab26581b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fnl_lst04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a8c5d-ed64-4a86-962b-e3d7517da96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Method to calculate the frequency of number of top N results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
